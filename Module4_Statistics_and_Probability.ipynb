{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOusb/4Ql/eKCzQE2D6CzDF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/otionrec/.github-workflows/blob/master/Module4_Statistics_and_Probability.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#There are two main branches of statistics\n",
        "\n",
        "Descriptive: description and representation of data\n",
        "\n",
        "Inferential: infer and make decisions from the data we have\n",
        "\n",
        "Types of Data\n",
        "Numerical\n",
        " and\n",
        "Categorical\n",
        "\n",
        "Types of Numerical Data\n",
        "Continuous: Interval(no true zero) or Ratio\n",
        " or\n",
        "Discrete\n",
        "\n",
        "\n",
        "Types of Categorical Data\n",
        "Nominal\n",
        " or\n",
        "Ordinal"
      ],
      "metadata": {
        "id": "uVapcY-rKJ6u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descriptive Statistics\n",
        "# Measure of Variability Part 1\n",
        "\n",
        "Outliers: an extreme value in the dataset that seems alien in comparison to all other values.\n",
        "\n",
        "Central Tendency\n",
        "-Tells us the location of the data\n",
        "-The three M's\n",
        "  - Mean\n",
        "  - Median\n",
        "  - Mode  \n",
        "\n",
        "Mean is taking the average of the data.\n",
        "It is greatly affected by outliers.\n",
        "\n",
        "Median tells us the middle value of a sorted dataset.\n",
        "- Formula: {(n + 1) / 2}th value (for odd number of data points)\n",
        "  - Where n is the size of the ordered dataset\n",
        "- Two rules to follow:\n",
        "  - Rule 1: If the size of the dataset n is an odd number, then the median is represented by the numerical value corresponding to the positioning point of the ordered observation\n",
        "  - Rule 2: If there is an even number of observations in the dataset, then the positioning point lies between the two observations in the middle of the dataset.\n",
        "- Median performs well in the presence of outliers\n",
        "\n",
        "Mode is the frequency of the dataset\n",
        "-Immune to outliers\n",
        "-A dataset can have two or more modes namely, Bimodal, Trimodal, Multimodal\n",
        "-A dataset can also have no mode\n",
        "\n",
        "# Summary\n",
        "- Mean is a good measure for a dataset without outliers\n",
        "- Median more accurately describes a data with outliers\n",
        "- Mode is good measure to use when we have categorical data\n",
        "\n"
      ],
      "metadata": {
        "id": "Mev1oAG9P4vY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Measure of Variability Part 2\n",
        " Variance, Standard deviation, Covariance\n",
        "\n",
        "-Variance measures the spread of data around the mean\n",
        "\n",
        "- Variance is a measure of how data points differ from the mean. According to Layman, a variance is a measure of how far a set of data (numbers) are spread out from their mean (average) value. Variance means to find the expected difference of deviation from actual value.\n",
        "\n",
        "Sample variance vs Population variance\n",
        "- Statisticians and Data scientists mostly deal with sample data and approximate parameters for the population\n",
        "- Sample variance is usually greater than population variance\n",
        "- The division by N-1 ensures that to compensate our lack of information about the population data\n",
        "\n",
        "- Standard Deviation is the Square root of variance\n",
        "- A standard deviation (or Ïƒ) is a measure of how dispersed the data is in relation to the mean. Low, or small, standard deviation indicates data are clustered tightly around the mean, and high, or large, standard deviation indicates data are more spread out.\n",
        "- We need Standard Deviation because Variance is too large for any visualization or comparison.\n",
        "\n",
        "Coefficient of Variation\n",
        "- is the Standard deviation divided by the mean\n",
        "-Dispersion of data relative to its mean\n",
        "-Useful in comparing two datasets\n",
        "- it is the ratio of the standard deviation to the mean. The higher the coefficient of variation, the greater the level of dispersion around the mean. It is generally expressed as a percentage.\n",
        "\n",
        "# Measures of Variable Relationship\n",
        "\n",
        "- Covariance measures the directional relationship between two variables\n",
        "- There are 3 types of COV\n",
        "- Positive COV: if one variable increases, and the second variable also increases\n",
        "- Negative COV: if one variable increases and the second variable decreases\n",
        "- Zero COV: no relation\n",
        "- It is directional because the positive and negative sign tells us the direction of the relationship\n",
        "\n",
        "Correlation\n",
        "-Covariance tells us the type of relationship two variables have\n",
        "-But correlations tells us how strong the relationship is, usually in percentage.\n",
        "\n"
      ],
      "metadata": {
        "id": "l3mqq9DSVxci"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inferential Statistics\n",
        "\n",
        "A distribution is a function that shows possible values for a variable & the frequency of their occurrence\n",
        "\n",
        "There are two types of distributions, thus Discrete and Continuous\n",
        "\n",
        "Discrete Distribution:\n",
        "- Uniform distribution ex. tossing a dice\n",
        "- Binomial distribution ex. tossing 2 dice\n",
        "- bar plots are used on discrete variables\n",
        "\n",
        "Continuous Distribution\n",
        "- Normal distribution also Gaussian dis.\n",
        "- Bell Curve\n",
        "- Mean = median = mode\n",
        "\n",
        "Standard Normal Distribution\n",
        "- we make mean = 0\n",
        "- and standard deviation = 1\n",
        "- z-score tells how mush the score is above or below the mean\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8yVYXy3LfEde"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Measures of Asymmetry\n",
        "\n",
        "- Measures imbalance or Asymmetry from the mean of a data distribution\n",
        "- Values concentrated on one side of the data distribution\n",
        "- Positive Skewness when the mean is almost always greater than the median and the values are concentrated on the right side of the peak of the distribution.\n",
        "- Negative Skewness is one with which the mean is almost always less than the median and the values are concentrated on the left side of the peak of the distribution.\n",
        "- Although Mode is mentioned, it is not considered when dealing with skewness\n",
        "\n",
        "Positive/Right Skewed\n",
        "- Tail on the right side is longer\n",
        "- It means that the outliers are on the right side\n",
        "\n",
        "Negative/Left  Skewed\n",
        "- It's when the tail is on the left side and it's elongated.\n",
        "- It means the outliers are on the left side\n",
        "\n"
      ],
      "metadata": {
        "id": "mz6zgB1bbmzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling Distribution\n",
        "\n",
        "- Sample statistics is more convinient and practical.\n",
        "- Extracting n samples from a population, each of size >= 30\n",
        "\n",
        "- Central Limit Theory: Regardless of the initial shape of the population distribution, sampling distribution will approximate to a normal distribution. As the sample size increases, sampling distribution will get narrower and more normal.\n",
        "- The essence of the CLT is that\n",
        "  -Population and sample mean should be equal. Thus the sample mean is approximated to the population mean\n",
        "  - The second info that we can genralize is its variance\n",
        "  -The population and sample variance can be approximated by the fact that we can calculate the standard error\n",
        "  -The standard error is when we divide the standard deviation by the square root of the number of samples\n",
        "\n",
        "- As the number of samples are greater than or equal to 30 , thus as we increase the value of n the sample distribution of the mean approximates to the normal distribution.\n",
        "\n",
        "\n",
        "- Confidence Intervals is the position or area under the graph which tells us the confidence level or how much we are confident about a particular distribution.\n",
        "- It has a lower limit and an upper limit\n",
        "- under the normal distribution, we can say that we are 95% sure that the mean and the other value lie in this particular region.\n",
        "\n",
        "- The confidence level is the percentage of times you expect to get close to the same estimate if you run your experiment again or resample the population in the same way. The confidence interval consists of the upper and lower bounds of the estimate you expect to find at a given level of confidence."
      ],
      "metadata": {
        "id": "UVar-lZ1e29P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Probability is the likelihood of an even occuring.\n",
        "- Expected values are the average outcome we expect if we run an experiment many times.\n",
        "- Trial: observing an event occur and recording outcome.\n",
        "  - Ex: Flipping a coin and recording the outcome.\n",
        "- Experiment: collection of one or more trials.\n",
        "  - Ex: Flipping a coin 10 times and recording 10 individual outcomes.\n",
        "- Experimental Probability: probability we assign and event, based on an experiment we conduct.  \n",
        "- In this instance, the experimental probability for getting tails would equal the number of tails we recorded over the course of the 10 outcomes, over 10(the total number of trails).\n",
        "-Expeced Value: the outcome we expect to occur when we run an experiment.\n",
        "\n",
        "# Relative Frequency\n",
        "- Relative frequency: The relative frequency of an event is defined as the number of times that the event occurs during experimental trials, divided but the total nimber of trials conducted.\n",
        "- Theoretical probability: a probability that is expected, for example when I flip a coin 100 times I expect tails to come up 50 times and heads to come up 50 times. The theoretical probability is 0.5 for a head. Not doing the actual experiment\n",
        "\n",
        "# Hypothesis Testing\n",
        "Hypothesis is an idea made from limited evidence. It is a starting point for further investigation. It is a 7-step process:\n",
        "- Make Assumptions: Assumptions are related to the distribution of data, sampling and linearity.\n",
        "- Take and initial position(Ho): The null hypothesis is the initial position. It is the statur-quo position. It is the position that is rejected or fails to be rejected. It is the position that needs to be validated. It is the position that needs to be tested.\n",
        "- Determine the alternate position(Ha): The alternate hypothesis is the contrary position to NULL hypothesis. If they're statistically significant evidence that suggest that the alternate hypothesis is valid, the the NULL hypothesis is rejected.\n",
        "- Set acceptance criteria: The NULL and alternate hypothesis is defined. he status-quo is the NULL hypothesis. Now, a threshold needs to be set.\n",
        "- Conduct fact-based tests: Here is where the testing is done. The Predictions are made & outcomes are noted.\n",
        "- Evaluate results: Does the evaluation support the initial position: Are we confident that the result is not due to chance?\n",
        "- Reach one of the following conclusion: Reject the original position in favor of alternate position or fail to reject the initial position.\n",
        "\n",
        "# Terminology\n",
        "\n",
        "-Null Hypothesis(Ho): the null hypothesis is the hypothesis to be tested for possible rejection under the assumption that it is true. The concept of the null is similar to innocent until proven guilty. It is denoted by Ho. If it is a test of means then we say that H0: u1 = u2, which states that there is no significant difference in the 2 population means.\n",
        "\n",
        "-Alternate Hypothesis(H1 of Ha): Null Hypothesis and Alternate Hypothesis are mutually exclusive statements. So if the Null Hypothesis is commonly accepted fact then the Alternate Hypothesis is a real fact based on observation from the sample data. It is denoted by H1 or Ha. If it is a test of means then we say that H1: u1 != u2, which states that there is a significant difference in 2 population means.\n",
        "\n",
        "# Simple & Composite Hypothesis Testing\n",
        "- When a hypothesis specifies an exact value of the parameter, it is a simple hypothesis and if it specifies a range of values then it is called a composite hypothesis.\n",
        "\n",
        "- A motocycle company claiming that a certain model gives an average mileage of 100 mpg, this is a case of simple hypothesis.\n",
        "- The average age of students in a class is greater than 20. This statement is a composite hypothesis.\n",
        "\n",
        "# One-tailed and Two-tailed Hypothesis Testing\n",
        "\n",
        "- If the alternate hypothesis gives the alternate in both directions ( less than and greater than) of the value of the parameter specified in the null hypothesis, it is called a Two-tailed test.\n",
        "- If the alternate hypothesis gives the alternate in only one direction (either less than or greater than) of the value of the parameter specified in the null hypothesis, it is called a One-tailed test.\n",
        "\n",
        "- Critical Region: also know a the rejection region, is a set of values for which the null hypothesis is rejected. The critical region is that region in the sample space in which if the calculated value lies then we reject the null hypothesis.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X8JJU7l9kWk7"
      }
    }
  ]
}